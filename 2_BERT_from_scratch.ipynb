{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtmCUntq2Sdp5SjWN3aOjw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clysdid/from_scratch/blob/master/2_BERT_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V8JpEr6o9a1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3가지 임베딩"
      ],
      "metadata": {
        "id": "WpgwDYVupRg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = 'bert from the very beginning'\n",
        "\n",
        "word_set = set(train_data.split())\n",
        "\n",
        "vocab = {tkn : i+2 for i, tkn in enumerate(word_set)}\n",
        "vocab['<unk>'] = 0\n",
        "vocab['<pad>'] = 1 # padding token 부분은 가중치가 업데이트 되지 않음.\n",
        "\n",
        "import torch.nn as nn #신경망 모델 상속\n",
        "embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=3, padding_idx=1)\n",
        "print(embedding_layer.weight)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp5oJSj6pOjZ",
        "outputId": "a2dcbcd4-7272-4333-d341-c6771ccf88c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.3541, -1.2216, -0.0734],\n",
            "        [ 0.0000,  0.0000,  0.0000],\n",
            "        [-0.2227,  1.4101,  0.1823],\n",
            "        [-1.3079,  0.0043,  0.3297],\n",
            "        [-1.0973, -0.7145, -1.1614],\n",
            "        [-0.5388,  1.5113, -0.5665],\n",
            "        [-0.9192, -0.1269,  1.7990]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer1 = nn.Embedding(num_embeddings=len(vocab), embedding_dim=2, padding_idx=1)\n",
        "print(embedding_layer1.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsKY5nRppOlm",
        "outputId": "867a85cf-4c5a-4935-80d9-f24fc7f76321"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.9095, -0.6470],\n",
            "        [ 0.0000,  0.0000],\n",
            "        [ 0.8001,  0.3543],\n",
            "        [ 0.6908, -0.4769],\n",
            "        [ 0.8480, -0.6338],\n",
            "        [ 0.7095,  0.3977],\n",
            "        [-0.9284, -0.5551]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. token embedding\n",
        "- 입력된 토큰에 대한 임베딩"
      ],
      "metadata": {
        "id": "PoCMPJZtKzou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class TokenEmbedding(nn.Embedding):\n",
        "  def __init__(self, vocab_size, embed_size=512):\n",
        "    super().__init__(vocab_size, embed_size, padding_idx =0)\n",
        ""
      ],
      "metadata": {
        "id": "p377J2tupOnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Segment Embedding\n",
        "- 두 문장 중 어디에 속하는지를 의미"
      ],
      "metadata": {
        "id": "-qtMKgI5LBqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentEmbedding(nn.Embedding):\n",
        "  def __init__(self, embed_size=512):\n",
        "    super().__init__(3, embed_size, padding_idx=0) # segment id가 3가지 종류 (2면 패딩, 0,1이면 각각 문장을 의미)"
      ],
      "metadata": {
        "id": "R8yTaJKppOph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. position embedding\n",
        "- 토큰 당 위치 정보"
      ],
      "metadata": {
        "id": "TTC43iQ_SGmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "class PositionalEmbedding(nn.Module):\n",
        "  def __init__(self, d_model, max_len=512):\n",
        "    super().__init__()\n",
        "\n",
        "    pe = torch.zeros(max_len, d_model).float()\n",
        "    pe.require_grad = False\n",
        "\n",
        "    position = torch.arange(0, max_len).float().unsqueeze(1)\n",
        "    div_term = (torch.arange(0, d_model, 2).float()* -(math.log(10000.0)/d_model)).exp()\n",
        "\n",
        "    pe[:, 0::2] = torch.sin(position*div_term)\n",
        "    pe[:, 1::2] = torch.cos(position*div_term)\n",
        "\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.pe[:, :x.size(1)]"
      ],
      "metadata": {
        "id": "U3QltvbXpOrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding all"
      ],
      "metadata": {
        "id": "GL6pekdOTPTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTEmbedding(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_size, dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.token = TokenEmbedding(vocab_size = vocab_size, embed_size = embed_size)\n",
        "    self.position = PositionalEmbedding(d_model = self.token.embedding_dim)\n",
        "    self.segment = SegmentEmbedding(embed_size = self.token.embedding_dim)\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.embed_size = embed_size\n",
        "\n",
        "  def forward(self, sequence, segment_label):\n",
        "    x = self.token(sequence) + self.position(sequence) + self.segment(segment_label)\n",
        "    return self.dropout(x)"
      ],
      "metadata": {
        "id": "U4tbD2OaTTt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pre-training: MLM & NSP"
      ],
      "metadata": {
        "id": "YPYmBxljVyAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. MLM"
      ],
      "metadata": {
        "id": "hPjRtyJJV33J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedLanguageModel(nn.Module):\n",
        "  def __init__(self, hidden, vocab_size):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(hidden, vocab_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.softmax(self.linear(x))"
      ],
      "metadata": {
        "id": "4EGueWlxV3HB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. NSP"
      ],
      "metadata": {
        "id": "IU_Oi0goWysA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NextSentencePrediction(nn.Module) :\n",
        "  def __init__(self, hidden):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(hidden, 2)\n",
        "    self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.softmax(self.linear(x[:,0]))"
      ],
      "metadata": {
        "id": "NVRqPEgbV3JN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "a = torch.tensor([[-0.9095, -0.6470],\n",
        "        [ 0.0000,  0.0000],\n",
        "        [ 0.8001,  0.3543],\n",
        "        [ 0.6908, -0.4769],\n",
        "        [ 0.8480, -0.6338],\n",
        "        [ 0.7095,  0.3977],\n",
        "        [-0.9284, -0.5551]])"
      ],
      "metadata": {
        "id": "F0yCSGohV3LT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_9poPqrV3Nx",
        "outputId": "399d74b5-ec19-4376-d86c-3e0476de452f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.squeeze(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlXQeZbEWktW",
        "outputId": "cacee9af-431f-496a-c213-b02fc6cff337"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9095, -0.6470],\n",
              "        [ 0.0000,  0.0000],\n",
              "        [ 0.8001,  0.3543],\n",
              "        [ 0.6908, -0.4769],\n",
              "        [ 0.8480, -0.6338],\n",
              "        [ 0.7095,  0.3977],\n",
              "        [-0.9284, -0.5551]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = a.unsqueeze(-1)\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4yYO3ZVWkva",
        "outputId": "1d43e7a5-c4bc-46d6-ae18-f507405d0678"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9095],\n",
              "         [-0.6470]],\n",
              "\n",
              "        [[ 0.0000],\n",
              "         [ 0.0000]],\n",
              "\n",
              "        [[ 0.8001],\n",
              "         [ 0.3543]],\n",
              "\n",
              "        [[ 0.6908],\n",
              "         [-0.4769]],\n",
              "\n",
              "        [[ 0.8480],\n",
              "         [-0.6338]],\n",
              "\n",
              "        [[ 0.7095],\n",
              "         [ 0.3977]],\n",
              "\n",
              "        [[-0.9284],\n",
              "         [-0.5551]]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HfmAV2fWsXr",
        "outputId": "28d9cd31-5f09-4080-bd95-16e7d1ba0169"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTLTM(nn.Module):\n",
        "  def __init__(self, bert : BERT, vocab_size):\n",
        "    super().__init__()\n",
        "    self.bert = bert\n",
        "    self.next_sentence = NextSentencePrediction(self.bert.hidden)\n",
        "    self.mask_lm = MaskedLanguageModel(self.bert.hidden, vocab_size)\n",
        "\n",
        "  def forward(self, x, segment_label):\n",
        "    x = self.bert(x, segment_label)\n",
        "    return self.next_sentence(x), self.mask_lm"
      ],
      "metadata": {
        "id": "xb15wAS0XJBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "IY1uokudYaBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "Tq1jPuMBYdkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTTrainer:\n",
        "  # 앞에 일부 생략\n",
        "  def __init__(self, bert: BERT, vocab_size: int,\n",
        "                 train_dataloader: DataLoader, test_dataloader: DataLoader = None,\n",
        "                 lr: float = 1e-4, betas=(0.9, 0.999), weight_decay: float = 0.01, warmup_steps=10000,\n",
        "                 with_cuda: bool = True, cuda_devices=None, log_freq: int = 10):\n",
        "\n",
        "    if with_cuda and torch.cuda.device_count()> 1:\n",
        "      self.model = nn.DataParallel(self.model, device_ids = cuda_devices)\n",
        "\n",
        "\n",
        "  def iteration(self, epoch, data_loader , train=True):\n",
        "    avg_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_element = 0\n",
        "\n",
        "    for i, data in data_iter:\n",
        "      # 0. batch data를 디바이스로 할당\n",
        "      data = {key:value.to(self.device) for key, value in data.items()}\n",
        "\n",
        "      # 1. forward nsp and mlm\n",
        "      next_sent_output, mask_lm_output = self.model.forward(data['bert_input'], data['segment_label'])\n",
        "\n",
        "      # 2. nll(negative log likelihood) of nsp\n",
        "      next_loss = self.criterion(next_sent_output, data['is_next'])\n",
        "\n",
        "      # 2-2 nll loss of mlm\n",
        "      mask_loss = self.criterion(mask_lm_output.transpose(1,2), data['bert_label']) # (batch_size, seq_length, embed_size)라면, transpose(1, 2)를 통해 (batch_size, embed_size, seq_length)로 바뀌게 됩니다.\n",
        "      #  loss 합\n",
        "      loss = next_loss + mask_loss\n",
        "\n",
        "     # backward and optimization\n",
        "      if train:\n",
        "        self.optim_schedule.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optim_schedule.step_and_update_lr()\n",
        "\n",
        "      # nsp 정확도\n",
        "      correct = next_sent_output.argmax(dim=-1).eq(data['is_next']).sum().item() # eq는 값이 같은지 비교\n",
        "      avg_loss += loss.item()\n",
        "      total_correct += correct\n",
        "      total_element += data['is_next'].nelement() # 몇개의 요소로 구성되어있는지"
      ],
      "metadata": {
        "id": "1Ro6W9xkYdmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3oDMUQywYdof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ix8EXnxYdq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8qnLCMAlYdtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://coaxsoft.com/blog/building-bert-with-pytorch-from-scratch\n",
        "- https://needmorecaffeine.tistory.com/31\n",
        "- https://github.com/codertimo/BERT-pytorch/tree/master"
      ],
      "metadata": {
        "id": "TdhE1bYUpO2S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2bT0b2cLpPVX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}